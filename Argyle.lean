import Mathlib.Tactic.LibrarySearch
import Mathlib.Tactic.NthRewrite
import Mathlib.Mathport.Syntax
import Std.Tactic.ShowTerm
import Lean.Meta.Tactic.Simp.Main
import Mathlib.Tactic.Basic

import Lean.Parser.Tactic
import Graph.Graph
import Graph.TopologicalSort
import Mathlib.Init.Set
import Mathlib.Data.List.Defs
import Mathlib.Init.Propext
import Mathlib.Data.Set.Basic
import Mathlib.Logic.Basic
import Mathlib.Logic.Function.Basic

open Graph
open Set
open Tactic
open Classical

-- Doesn't detect inefficient code!
set_option maxHeartbeats 0

-------------------------------------------------
-- Goofing about with inductive types
-------------------------------------------------

inductive my_lte : â„• â†’ â„• â†’ Prop where
  | reflexive : my_lte n n
  | from_succ : my_lte m x â†’ (n = x + 1) â†’ my_lte m n

-- #eval my_lte 1 3



-------------------------------------------------
-- Extract Lets Tactic
-------------------------------------------------
/-
Copyright (c) 2023 Kyle Miller. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Kyle Miller
-/

/-!
# The `extract_lets at` tactic
This module defines a tactic `extract_lets ... at h` that can be used to (in essence) do `cases`
on a `let` expression.
-/


-- open Lean Elab Parser Meta Tactic

-- /-- Given a local hypothesis whose type is a `let` expression, then lift the `let` bindings to be
-- a new local definition. -/
-- def Lean.MVarId.extractLetsAt (mvarId : MVarId) (fvarId : FVarId) (names : Array Name) :
--     MetaM (Array FVarId Ã— MVarId) := do
--   mvarId.checkNotAssigned `extractLetAt
--   mvarId.withReverted #[fvarId] fun mvarId fvarIds => mvarId.withContext do
--     let mut mvarId := mvarId
--     let mut fvarIds' := #[]
--     for name in names do
--       let ty â† Lean.instantiateMVars (â† mvarId.getType)
--       mvarId â† match ty with
--         | .letE n t v b ndep => process mvarId t (.letE n Â· v b ndep)
--         | .forallE n t v b   => process mvarId t (.forallE n Â· v b)
--         | _ => throwTacticEx `extractLetAt mvarId "unexpected auxiliary target"
--       let (fvarId', mvarId') â† mvarId.intro name
--       fvarIds' := fvarIds'.push fvarId'
--       mvarId := mvarId'
--     return (fvarIds', fvarIds.map .some, mvarId)
-- where
--   /-- Check that `t` is a `let` and then do what's necessary to lift it over the binding
--   described by `mk`. -/
--   process (mvarId : MVarId) (t : Expr) (mk : Expr â†’ Expr) : MetaM MVarId := do
--     let .letE n' t' v' b' _ := t.cleanupAnnotations
--       | throwTacticEx `extractLetAt mvarId "insufficient number of `let` expressions"
--     -- Lift the let
--     withLetDecl n' t' v' fun fvar => do
--       let b' := b'.instantiate1 fvar
--       let ty' â† mkLetFVars #[fvar] <| mk b'
--       mvarId.change ty'

-- /-- Counts the immediate depth of a nested `let` expression. -/
-- def Lean.Expr.letDepth : Expr â†’ Nat
--   | .letE _ _ _ b _ => b.letDepth + 1
--   | _ => 0

-- /-- A more limited version of `Lean.MVarId.introN` that ensures the goal is a
-- nested `let` expression. -/
-- def Lean.MVarId.extractLets (mvarId : MVarId) (names : Array Name) :
--     MetaM (Array FVarId Ã— MVarId) :=
--   mvarId.withContext do
--     let ty := (â† Lean.instantiateMVars (â† mvarId.getType)).cleanupAnnotations
--     if ty.letDepth < names.size then
--       throwTacticEx `extractLet mvarId "insufficient number of `let` expressions"
--     mvarId.introN names.size names.toList

-- namespace Mathlib

-- /-- The `extract_lets at h` tactic takes a local hypothesis of the form `h : let x := v; b`
-- and introduces a new local definition `x := v` while changing `h` to be `h : b`.  It can be thought
-- of as being a `cases` tactic for `let` expressions. It can also be thought of as being like
-- `intros at h` for `let` expressions.
-- For example, if `h : let x := 1; x = x`, then `extract_lets x at h` introduces `x : Nat := 1` and
-- changes `h` to `h : x = x`.
-- Just like `intros`, the `extract_lets` tactic either takes a list of names, in which case
-- that specifies the number of `let` bindings that must be extracted, or it takes no names, in which
-- case all the `let` bindings are extracted.
-- The tactic `extract_let at âŠ¢` is a weaker form of `intros` that only introduces obvious `let`s. -/
-- syntax (name := extractLets) "extract_lets " (colGt (ident <|> hole))* (ppSpace location) : tactic

-- @[tactic Mathlib.extractLets] def evalExtractLet : Tactic := fun stx => do
--   match stx with
--   | `(tactic| extract_lets $loc:location)         => doExtract none loc
--   | `(tactic| extract_lets $hs* $loc:location)    => doExtract hs loc
--   | _ => throwUnsupportedSyntax
-- where
--   setupNames (ids? : Option (TSyntaxArray [`ident, `Lean.Parser.Term.hole])) (ty : Expr) :
--       MetaM (Array Name) := do
--     if let some ids := ids? then
--       return ids.map getNameOfIdent'
--     else
--       return Array.mkArray (â† instantiateMVars ty).cleanupAnnotations.letDepth `_
--   doExtract (ids? : Option (TSyntaxArray [`ident, `Lean.Parser.Term.hole]))
--       (loc : TSyntax `Lean.Parser.Tactic.location) :
--       TacticM Unit := do
--     let process (f : MVarId â†’ Array Name â†’ MetaM (Array FVarId Ã— MVarId))
--         (ty : MVarId â†’ MetaM Expr) : TacticM Unit := do
--       let fvarIds â† liftMetaTacticAux fun mvarId => do
--         let ids â† setupNames ids? (â† ty mvarId)
--         let (fvarIds, mvarId) â† f mvarId ids
--         return (fvarIds, [mvarId])
--       if let some ids := ids? then
--         withMainContext do
--           for stx in ids, fvarId in fvarIds do
--             Term.addLocalVarInfo stx (.fvar fvarId)
--     withLocation (expandOptLocation (mkOptionalNode loc))
--       (atLocal := fun h â†¦ do
--         process (fun mvarId ids => mvarId.extractLetsAt h ids) (fun _ => h.getType))
--       (atTarget := do
--         process (fun mvarId ids => mvarId.extractLets ids) (fun mvarId => mvarId.getType))
--       (failed := fun _ â†¦ throwError "extract_let tactic failed")

-- end Mathlib


-------------------------------------------------
-- List comprehensions,
-- courtesy of lovettchris
-- See: 
--   https://github.com/leanprover/lean4-samples/blob/main/ListComprehension/ListComprehension.lean
-------------------------------------------------

declare_syntax_cat compClause
syntax "for " term " in " term : compClause
syntax "if " term : compClause

syntax "[" term " | " compClause,* "]" : term

def List.map' (xs : List Î±) (f : Î± â†’ Î²) : List Î² := List.map f xs

macro_rules
  | `([$t:term |]) => `([$t])
  | `([$t:term | for $x in $xs]) => `(List.map' $xs  (Î» $x => $t))
  | `([$t:term | if $x]) => `(if $x then [$t] else [])
  | `([$t:term | $c, $cs,*]) => `(List.join [[$t | $cs,*] | $c])

def prod_comprehens (xs : List Î±) (ys : List Î²) : List (Î± Ã— Î²) := 
  [(x, y) | for x in xs, for y in ys]

#eval [(x, y) | for x in [1, 2], for y in [3, 4]]

-------------------------------------------------
-- intro_lets tactic
-- https://leanprover.zulipchat.com/#narrow/stream/217875-Is-there-code-for-X.3F/topic/Pulling.20.60let.60s.20to.20the.20outside.20of.20a.20statement/near/315581119
-- Courtesy of Eric Wieser
-- 
-------------------------------------------------
-- This is written in Lean 3!
-- I need this but for Lean 4...

-- meta def mk_local_lets : expr â†’ tactic (list expr Ã— expr)
-- | (expr.elet n d v b) := do
--   p â† tactic.definev n d v,
--   (ps, r) â† mk_local_lets (expr.instantiate_var b p),
--   return ((p :: ps), r)
-- | (expr.app f x) := do
--     (fargs, f) â† mk_local_lets f,
--     (xargs, x) â† mk_local_lets x,
--     pure (fargs ++ xargs, f.app x)
-- | e := return ([], e)

-- meta def tactic.interactive.lift_lets : tactic unit :=
-- do
--   (lets, t) â† tactic.target >>= mk_local_lets,
--   tactic.change t

-------------------------------------------------
-- Graphs
-------------------------------------------------
-- This is a graph with â„• nodes
-- and Float edge weights.
def graphA : Graph â„• Float :=
  âŸ¨#[
    âŸ¨0, #[âŸ¨1, 0.5âŸ©, âŸ¨2, 0.6âŸ©, âŸ¨3, 0.7âŸ©]âŸ©, 
    âŸ¨1, #[âŸ¨2, 0.8âŸ©, âŸ¨3, 0.9âŸ©]âŸ©, 
    âŸ¨2, #[âŸ¨3, 1.0âŸ©, âŸ¨3, 5.0âŸ©]âŸ©, 
    âŸ¨3, #[]âŸ©
  ]âŸ©

#check graphA
#eval graphA
#eval graphA.edgeCount   -- evals to 7
#eval graphA.order       -- evals to 4
#eval graphA.toArray     -- evals to #[0, 1, 2, 3]

#eval graphA.inDegree 1      -- evals to 1
#eval graphA.outDegree 1     -- evals to 2
#eval graphA.successors 1    -- evals to #[2, 3]
#eval graphA.predecessors 1  -- evals to #[0]

#eval graphA.inDegree 2      -- evals to 2
#eval graphA.outDegree 2     -- evals to 2
#eval graphA.successors 2    -- evals to #[3, 3]
#eval graphA.predecessors 2  -- evals to #[0, 1]

-------------------------------------------------
-- My own graph functions and convenience
-- properties
-------------------------------------------------
namespace Graph
variable {Î± : Type} [Inhabited Î±] {Î² : Type}

def hasNode (g : Graph Î± Î²) (v : â„•) : Bool :=
  g.getAllVertexIDs.contains v

def hasEdge (g : Graph Î± Î²) (u v : â„•) : Bool :=
  (g.successors u).contains v

#eval hasEdge graphA 1 2
#eval hasEdge graphA 1 3
#eval hasEdge graphA 4 2

def getEdgeWeight (g : Graph Î± Î²) (u v : â„•) : Î² :=
  sorry

inductive hasPath (g : Graph â„• Î²) : â„• â†’ â„• â†’ Prop where
  | trivial {u : â„•} :
      hasPath g u u
  | from_path {u v w : â„•} : 
      hasPath g u v â†’ hasEdge g v w â†’ hasPath g u w

instance decPath : Decidable (hasPath g u v) :=
  sorry -- this should implement BFS!!!
  -- if h : u = v then
  --   isTrue (Eq.subst h hasPath.trivial)
  -- else if h : hasEdge g u v then
  --   isTrue (hasPath.from_path (hasPath.trivial) h)
  -- else
  --   sorry

/-
instance decLte : Decidable (my_lte m n) :=
  if h : m = n then
    .isTrue (h â–¸ .trivial)
  else
    match n with
    | x + 1 =>
      have := @decLte m x
      decidable_of_iff (my_lte m x) âŸ¨(.from_path Â· rfl), fun h => by
        cases h with
        | trivial => cases h rfl
        | from_path h e => exact Nat.succ.inj e â–¸ hâŸ©
    | 0 => .isFalse fun h => by
      cases h with
      | trivial => exact h rfl
      | from_path h e => cases e
-/


  -- deriving DecidableEq
  -- TODO: Make graph computable so that we can execute this code:
  -- #eval hasPath graphA 1 3

theorem hasPath_trans {u v w : â„•} (g : Graph â„• Î²) :
  hasPath g u v â†’ hasPath g v w â†’ hasPath g u w := by

  intro (hâ‚ : hasPath g u v)
  intro (hâ‚‚ : hasPath g v w)

  induction hâ‚‚
  case trivial => exact hâ‚
  case from_path x y path_vx edge_xy path_ux => 
    exact hasPath.from_path path_ux edge_xy


def is_refl (g : Graph Î± Î²) : Prop :=
  âˆ€ (u : â„•),
    g.hasNode u â†’ g.hasEdge u u

def is_symm (g : Graph Î± Î²) : Prop :=
  âˆ€ (u v : â„•),
    g.hasEdge u v â†’ g.hasEdge v u

def is_trans (g : Graph Î± Î²) : Prop :=
  âˆ€ (u v w : â„•),
    g.hasEdge u v â†’ g.hasEdge v w â†’ g.hasEdge u w

def is_acyclic (g : Graph â„• Î²) : Prop :=
  âˆ€ (u v : â„•),
    g.hasPath u v â†’ g.hasPath v u â†’ u = v

end Graph

namespace TopologicalSort

-- match net.graph with
--   | _ => true if ... false ow
--   | _ => true if ... false ow

-- holds iff u precedes v in array
-- note that we assume lst elements are all distinct
def list_precedes (lst : List â„•) (u v : â„•) : Bool :=
  match lst with
    | List.nil => false
    | List.cons x xs =>
      -- If we find 'u' first, and v is in the rest, true
      if x = u âˆ§ v âˆˆ xs then 
        true
      else 
        list_precedes xs u v

def listA : List â„• :=
  [2, 4, 9, 8, 5]

-- a couple of unit tests for good measure
#eval list_precedes listA 4 8 -- true
#eval list_precedes listA 2 8 -- true
#eval list_precedes listA 2 4 -- true
#eval list_precedes listA 2 9 -- true
#eval list_precedes listA 9 5 -- true

#eval list_precedes listA 8 2 -- should be false, is true
#eval list_precedes listA 5 9 -- should be false, is true

#eval list_precedes listA 1 7 -- undefined (false)
#eval list_precedes listA 9 9 -- false, makes sure an element
                              -- does not precede itself.

-- The ordering induced by Topological Sort
-- TODO: Rewrite as an inductive data type!
/-
def topOrder (g : Graph â„• Î²) (u v : â„•) : Prop :=
  match (topSort g) with
    | some sorted => list_precedes sorted.toList u v
    | none => sorry
-/

-- inductive TopologicalOrdering (g : Graph â„• Î²) (u : â„•) where
--   | constr1 : TopologicalOrdering g u
--   | constr2 (x : â„•) : TopologicalOrdering g u

-- inductive graph_â‰º (g : Graph â„• Î²) (u v : â„•) where
--   | constr1 : sorry
--   | constr2 : sorry



-- Says that Topological Sort is actually correct, i.e.
-- if there is an edge from x to y, then x â‰º y in the ordering.
-- theorem topSort_is_ordered (g : Graph â„• Î²) (u v : â„•) :
--   g.hasEdge u v â†’ topOrder g u v := by

--   intro (hâ‚ : hasEdge g u v)
--   rw [topOrder]
--   sorry

end TopologicalSort

-------------------------------------------------
-- Example:  Our graphA is acyclic
-------------------------------------------------
theorem graphA_is_acyclic : graphA.is_acyclic := by
  intro (u : â„•) (v : â„•)
        (path_uv : hasPath graphA u v)
        (path_vu : hasPath graphA v u)

  sorry

  -- TODO: Is there a way to just do cases on the specific
  -- elements of 'graphA'?  Probably if I restrict it to 'Fin'...

  -- induction path_uv
  -- case trivial => rfl
  -- case from_path xâ‚ yâ‚ path_uxâ‚ edge_xâ‚yâ‚ IHâ‚ => 
    
  --   induction path_vu
  --   case trivial => rfl
  --   case from_path xâ‚‚ yâ‚‚ path_yâ‚xâ‚‚ edge_xâ‚‚yâ‚‚ IHâ‚‚ => 
  --     sorry

-- exact have (path_xu : hasPath graphA x u) := sorry

-------------------------------------------------
-- Activation functions
-------------------------------------------------
def binary_step (x : Float) : Float :=
  if x > 0.0 then
    1.0
  else
    0.0

axiom le_refl_float : âˆ€ (x : Float), x â‰¤ x
axiom lt_or_ge_float : âˆ€ (x y : Float), x < y âˆ¨ x â‰¥ y
axiom le_not_lt_float : âˆ€ (x y : Float), x â‰¤ y â†’ Â¬ (y < x)
axiom lt_le_lt_float : âˆ€ (x y z : Float), x < y â†’ y â‰¤ z â†’ x < z
axiom zero_le_one_float : 0.0 â‰¤ 1.0

theorem binary_step_is_binary (x : Float) :
    (binary_step x = 0.0) âˆ¨ (binary_step x = 1.0) :=
    by
      -- simp [binary_step]

      cases (lt_or_ge_float 0.0 x) with

      -- Case 1: 0.0 < x
      | inl case1 =>
          have (h : binary_step x = 1.0) :=
            by
              simp only [binary_step]
              rw [(if_pos case1)]
          exact Or.inr h

      -- Case 2: Â¬ (0.0 < x)
      | inr case2 =>
          have (h : binary_step x = 0.0) := 
            by 
              simp only [binary_step]
              rw [(if_neg (le_not_lt_float x 0.0 case2))]
          exact Or.inl h

-- Proof that binary_step is nondecreasing
-- This is also a 'hello world' to see if I can
-- reason about a branching program.
theorem binary_step_nondecr (xâ‚ xâ‚‚ : Float) (hyp : xâ‚ â‰¤ xâ‚‚) :
  (binary_step xâ‚ â‰¤ binary_step xâ‚‚) := 
  by
    -- Simplify by applying the definition of binary_step.
    simp [binary_step]
    
    cases (lt_or_ge_float 0.0 xâ‚) with
    | inl case1 =>
      cases (lt_or_ge_float 0.0 xâ‚‚) with
      | inl case11 => 
          -- Both sides evaluate to 1.0,
          -- so we just prove that 1.0 â‰¤ 1.0.
          rw [(if_pos case1)]
          rw [(if_pos case11)]
          exact le_refl_float 1.0
      | inr case12 => 
          -- We have 0.0 < xâ‚ â‰¤ xâ‚‚ < 0.0,
          -- so this case is absurd. 
          exact absurd
            (lt_le_lt_float 0.0 xâ‚ xâ‚‚ case1 hyp) -- library_search!!! 
            (le_not_lt_float xâ‚‚ 0.0 case12)
    | inr case2 => 
      cases (lt_or_ge_float 0.0 xâ‚‚) with
      | inl case21 => 
          -- We are in the second and first cases.
          rw [(if_neg (le_not_lt_float xâ‚ 0.0 case2))]
          rw [(if_pos case21)]
          exact zero_le_one_float
      | inr case22 => 
          rw [(if_neg (le_not_lt_float xâ‚ 0.0 case2))]
          rw [(if_neg (le_not_lt_float xâ‚‚ 0.0 case22))]
          exact le_refl_float 0.0 -- library_search!!!

-------------------------------------------------
-- Feedforward neural nets
-------------------------------------------------
structure Net where
  graph : Graph â„• Float
  activation : Float â†’ Float
  rate : Float -- learning rate

structure BFNN extends Net where 
  -- The activation function is binary
  binary : âˆ€ (x : Float), 
    (activation x = 0.0) âˆ¨ (activation x = 1.0)

  -- Our graph is acyclic
  acyclic : graph.is_acyclic

  -- The activation function is nondecreasing
  activ_nondecr : âˆ€ (xâ‚ xâ‚‚ : Float),
    xâ‚ â‰¤ xâ‚‚ â†’ activation xâ‚ â‰¤ activation xâ‚‚

  -- There is *some* x for which the activation is 1.0
  activ_pos : âˆƒ (x : Float), activation x = 1.0

def myBFNN : BFNN :=
  {
    graph := graphA
    activation := binary_step
    rate := 1.0

    binary := binary_step_is_binary
    -- sort := (topSortUnsafe graphA).toList.reverse
    acyclic := graphA_is_acyclic
    activ_nondecr := binary_step_nondecr
    activ_pos := sorry
  }

-- inductive Layer (net : BFNN) : List â„• â†’ Prop where
--   | initial_layer : Layer net Nâ‚€
--   | next_layer : âˆ€ (n : â„•), (n âˆˆ N â†’ 
--     âˆƒ (m : â„•), m âˆˆ Náµ¢ âˆ§ Layer net Náµ¢) â†’ Layer net N

variable (net : BFNN)

-------------------------------------------------
-- Playing around with Sets
-------------------------------------------------

def setA : Set â„• :=
  {n | n â‰¤ 10}

def setB : Set â„• :=
  {n âˆˆ setA | n > 5}

def setC : Set â„• :=
  {n | n â‰¤ 5}

#check setA

-- Example proof of a subset, just to make
-- sure I can do it.
example : setB âŠ† setA := by
  intro (n : â„•)
  intro (h : n âˆˆ setB)

  exact show n âˆˆ setA from h.left

-- Another example proof of a subset, this
-- time using the RHS of the set comprehension.
example : setC âŠ† setA := by
  intro (n : â„•)
  intro (hâ‚ : n âˆˆ setC)

  have (hâ‚‚ : n â‰¤ 5) := hâ‚
  have (hâ‚ƒ : 5 â‰¤ 10) := (by native_decide)
  exact show n âˆˆ setA from le_trans hâ‚‚ hâ‚ƒ


-- Prove that a set is contained in its powerset
example : âˆ€ (S : Set Î±), S âˆˆ ğ’« S := by
  intro (S : Set Î±)
  intro (a : Î±)
  intro (h : a âˆˆ S)
  exact h


-- TODO Next: Define graph reachability and propagate
-- Prove that the above BFNN is acyclic, just to make sure
-- we have the right tools for the job.


theorem setExample : 3 âˆˆ setC := by 
  have (hâ‚ : 3 â‰¤ 4) := by native_decide
  constructor
  exact hâ‚



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Forward propagation in a net
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

def weighted_sum (weights : List Float) (lst : List Float) : Float :=
  List.sum [w * x | for w in weights, for x in lst]

#eval weighted_sum [] []
#eval weighted_sum [1.0] [3.0]
#eval weighted_sum [1.0, 2.0, 3.0] [5.0, 5.0, 5.0]

-- Not well-defined behavior (we expect the weights and lst to be of equal size,
-- but this is left implicit.)
#eval weighted_sum [1.0, 2.0] [3.0]

-- WARNING:
-- This is actually FALSE!  For infinite sets, l[i] is not provably
-- in l (as far as I can figure.)
-- TODO: In the future, when making all this computable, I will
-- be using finite sets, and then I can use get instead of get!,
-- and get_mem in the standard library.
axiom get!_mem {Î± : Type} [Inhabited Î±] : 
  âˆ€ (l : List Î±) i, (l.get! i) âˆˆ l

@[simp]
def preds (net : BFNN) (n : â„•): List â„• :=
  (predecessors net.toNet.graph n).toList

-- inductive hasPath (g : Graph â„• Î²) : â„• â†’ â„• â†’ Prop where
--   | trivial {u : â„•} :
--       hasPath g u u
--   | from_path {u v w : â„•} : 
--       hasPath g u v â†’ hasEdge g v w â†’ hasPath g u w

-- -- OLD ACTIV FUNCTION
-- noncomputable
-- def activ (S : Set â„•) (n : â„•) : Bool :=
--   let preds := preds net n
--   -- We use 'do' to do a list comprehension.
--   -- Notice that we're collecting the *indices*.  This gives
--   -- us more information later;
--   -- to prove m âˆˆ preds, we can instead prove preds[i] âˆˆ preds.
--   let prev_activ := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return if m âˆˆ S then 1.0 else 0.0
--   let weights := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return net.graph.getEdgeWeight m n
--   let weight_sum := weighted_sum weights prev_activ
--   let curr_activ := net.activation weight_sum
--   if curr_activ = 1.0 then 
--     true
--   else false

-- -- We need another lemma about 'activ'...!

-- -- If A and B agree on all the predecessors of n, then they agree on n.
-- -- TODO: We don't seem to need this lemma anymore!
-- lemma activ_agree (net : BFNN) (A B : Set â„•) (n : â„•) :
--   let preds := preds net n
--   (âˆ€ (m : â„•), m âˆˆ preds â†’ (m âˆˆ A â†” m âˆˆ B))
--   â†’ activ net A n
--   â†’ activ net B n := by

--   intro preds
--         (hâ‚ : âˆ€ (m : â„•), m âˆˆ preds â†’ (m âˆˆ A â†” m âˆˆ B))
--         (hâ‚‚ : activ net A n)

--   -- The two are definitionally equal; just go in and
--   -- substitute all of the preceding m's 
--   simp only [activ]
--   simp only [activ] at hâ‚‚
--   convert â† hâ‚‚ using 7
  
--   rename_i i
--   let m := preds.get! i
--   have hâ‚ƒ : m âˆˆ preds := get!_mem preds i
--   congr 2
--   apply Iff.to_eq
--   exact hâ‚ m hâ‚ƒ


-- OLD PROPAGATION
-- For a single node, propagateâ‚š holds iff that node is n âˆˆ S. 
-- Otherwise, check if we are looking at n.  If so,
-- propagateâ‚š holds iff either:
--   1. n âˆˆ S, or
--   2. The nodes m preceding n activate n.
--      (We check their activation values via propagateâ‚š on m)
-- If we aren't looking at n, just continue recursively.
-- 
-- This is recursion on the topological ordering of the graph!!!
-- (We can only do this because the graph is acyclic, but
--  that fact is implicit if we use topSortUnsafe.)
-- 
-- TODO: Make this computable!!!
-- change return type to 'Bool' instead of 'Prop'
-- and change 'Set' to be a finite set
-- and change net.graph to be finite as well!
-- 
-- Then unit-test all this with #eval!

-- Can I make this into an inductive type, and then do
-- induction over it?  (That gives me an IH; match does not.)

-- Note that Set â„• is just defined as â„• â†’ Prop!
-- This simplifies our definitions.
-- @[simp]
-- def propagate (net : BFNN) (S : Set â„•) (sort : List â„•) : Set â„• :=
--   fun (n : â„•) =>
--     match sort with
--     | [] => n âˆˆ S
--     | x :: xs => 
--       if x = n then
--         n âˆˆ S âˆ¨ activ net {m | m âˆˆ propagate net S xs} n
--       else
--         n âˆˆ propagate net S xs

-- (Weightless) graph distance from node m to n.  Just count
-- the number of edges, i.e. don't apply weights.
def distance (graph : Graph â„• Float) (m n : â„•) : â„• :=
  sorry

def layer (net : BFNN) (n : â„•) : â„• :=
  sorry

-- AXIOM: We assume the net is fully connected!
-- This is essentially the statement we need, which might
-- follow from being fully connected.
-- TODO: Put this in the definition of BFNN!!!
axiom connected : âˆ€ (net : BFNN) (m n : â„•), 
  layer net m < layer net n â†’ net.graph.hasEdge m n

-- If m is a predecessor of n, then there is a path
-- from m to n.
lemma preds_path (net : BFNN) :
  m âˆˆ preds net n
  â†’ hasPath net.graph m n := by
  sorry

-- If m is a predecessor of n, then it must be in a previous layer.
lemma preds_decreasing (net : BFNN) (m n : â„•) :
  m âˆˆ preds net n 
  â†’ layer net m < layer net n := by
  sorry

noncomputable
def activ (net : BFNN) (prev_activ : List Float) (n : â„•) : Prop :=
  let preds := preds net n
  let weights := do
    let i <- List.range preds.length
    let m := preds.get! i
    return net.graph.getEdgeWeight m n
  let weight_sum := weighted_sum weights prev_activ
  let curr_activ := net.activation weight_sum
  curr_activ = 1.0

/-
activ net
  (List.bind (List.range (List.length (predecessors net.toNet.graph n).data)) fun i =>
    pure
      (if
          propagate_acc net (fun n => propagate_acc net S n (layer net n))
            (List.get! (predecessors net.toNet.graph n).data i)
            (layer net (List.get! (predecessors net.toNet.graph n).data i)) then
        OfScientific.ofScientific 10 true 1
      else OfScientific.ofScientific 0 true 1))
  n
-/

-- Accumulator variation of propagate
-- (We accumulate the layer of the net that n is in)
@[simp]
def propagate_acc (net : BFNN) (S : Set â„•) (n : â„•) (L : â„•) : Prop :=
  match L with
  | Nat.zero => n âˆˆ S
  | Nat.succ k =>
    let preds := preds net n
    let prev_activ := do
      let i <- List.range preds.length
      let m := preds.get! i
      return if propagate_acc net S m (layer net m) then 1.0 else 0.0
    n âˆˆ S âˆ¨ activ net prev_activ n
termination_by propagate_acc net S n L => layer net n
decreasing_by exact preds_decreasing net m n (get!_mem preds i)


-- Set variation of propagate
@[simp]
def propagate (net : BFNN) (S : Set â„•) : Set â„• :=
  fun n => propagate_acc net S n (layer net n)

-- @[simp]
-- def topol_sort (g : Graph â„• Float) :=
--   (topSortUnsafe g).toList.reverse

-------------------------------------------------
-- Some helper lemmas
-- (just to clean up the monstrous proofs ahead!)
-- 
-- TODO: Clean these up with nicer @simp lemmas about
-- propagate and activ
-------------------------------------------------

--------------------------------------------------------------------
lemma simp_propagate_acc (net : BFNN) :
  n âˆ‰ S
  â†’ propagate_acc net S n (Nat.succ L) =
  let preds := preds net n
  let prev_activ := do
    let i <- List.range preds.length
    let m := preds.get! i
    return if propagate_acc net S m (layer net m) then 1.0 else 0.0
  activ net prev_activ n := by
--------------------------------------------------------------------
  intro (hâ‚ : n âˆ‰ S)
  apply Iff.to_eq
  apply Iff.intro

  case mp => 
    intro hâ‚‚
    simp only [propagate_acc]
    simp only [propagate_acc] at hâ‚‚
    
    cases hâ‚‚
    case inl hâ‚ƒ => contradiction
    case inr hâ‚ƒ => exact hâ‚ƒ 
  
  case mpr => 
    intro hâ‚‚
    simp only [propagate_acc]
    simp only [propagate_acc] at hâ‚‚
    exact Or.inr hâ‚‚

-- -- If A and B agree on all the predecessors of n, then they agree on n.
-- -- TODO: We don't seem to need this lemma anymore!
-- lemma activ_agree (net : BFNN) (A B : Set â„•) (n : â„•) :
--   let preds := preds net n
--   (âˆ€ (m : â„•), m âˆˆ preds â†’ (m âˆˆ A â†” m âˆˆ B))
--   â†’ activ net A n
--   â†’ activ net B n := by

-- If A and B agree on all the predecessors of n, then they agree on n.
--------------------------------------------------------------------
-- lemma activ_agree (net : BFNN) (A B : Set â„•) (n : â„•) :
--   let preds := preds net n
--   let prevâ‚ := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return if m âˆˆ A then 1.0 else 0.0
--   let prevâ‚‚ := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return if m âˆˆ B then 1.0 else 0.0

--   (âˆ€ (m : â„•), m âˆˆ preds â†’ (m âˆˆ A â†” m âˆˆ B))
--   â†’ activ net prevâ‚ n
--   â†’ activ net prevâ‚‚ n := by
-- --------------------------------------------------------------------
--   -- let preds := preds net n
--   intro preds
--   intro prevâ‚
--   intro prevâ‚‚
--   intro (hâ‚ : âˆ€ (m : â„•), m âˆˆ preds â†’ (m âˆˆ A â†” m âˆˆ B))
--   intro (hâ‚‚ : activ net prevâ‚ n)
  
--   simp only [activ]
--   simp only [activ] at hâ‚‚
--   convert â† hâ‚‚ using 7

--   rename_i i
--   let m := preds.get! i
--   have hâ‚ƒ : m âˆˆ preds := get!_mem preds i
--   exact hâ‚ m hâ‚ƒ

-- If A and B agree on all the predecessors of n, then they agree on n.
--------------------------------------------------------------------
-- lemma activ_agree (net : BFNN) (A B : Set â„•) (n : â„•) :
--   (âˆ€ (m : â„•), layer net m â‰¤ layer net n â†’ (m âˆˆ A â†” m âˆˆ B))
  
--   â†’ (let preds := preds net n
--   let prev_activ := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return if m âˆˆ A then 1.0 else 0.0
--   activ net prev_activ n)
  
--   â†’ (let preds := preds net n
--   let prev_activ := do
--     let i <- List.range preds.length
--     let m := preds.get! i
--     return if m âˆˆ B then 1.0 else 0.0
--   activ net prev_activ n) := by
-- --------------------------------------------------------------------
--   -- Just go in and subsitute m âˆˆ A for m âˆˆ B.
--   intro (hâ‚ : âˆ€ (m : â„•), layer net m â‰¤ layer net n â†’ (m âˆˆ A â†” m âˆˆ B))
--   intro hâ‚‚
  
--   simp
--   simp at hâ‚‚
--   convert hâ‚‚ using 5
--   rename_i i
--   generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
--   -- generalize hLm : layer net m = Lm

--   have hâ‚ƒ : m âˆˆ preds net n := by
--     rw [symm hm]
--     simp [preds]
--     exact get!_mem (predecessors net.toNet.graph n).data i
--   have hâ‚„ : layer net m â‰¤ layer net n := by
--     apply le_of_lt
--     exact preds_decreasing net m n hâ‚ƒ
--   exact (symm (hâ‚ m hâ‚„).to_eq).to_iff

-- If A and B agree on all the predecessors of n, 
-- then the corresponding activ's agree on n.
-- lemma activ_agree (net : BFNN) (A B : Set â„•) (n : â„•) :
--   (âˆ€ (m : â„•), layer net m â‰¤ layer net n â†’ (m âˆˆ A â†” m âˆˆ B))
  
--   â†’ (activ net
--       (List.bind (List.range (preds net n).length) fun i =>
--         pure (if propagate_acc net 
--               (fun n => propagate_acc net S n (layer net n)) ((preds net n).get! i)
--                     (layer net ((preds net n).get! i)) 
--               then 1.0 else 0.0)) n)
  
--   â†’ (activ net
--       (List.bind (List.range (List.length (preds net n))) fun i =>
--         pure (if propagate_acc net S ((preds net n).get! i)
--               (layer net ((preds net n).get! i)) 
--               then 1.0 else 0.0)) n) := by
-- --------------------------------------------------------------------
--   intro (hâ‚ : âˆ€ (m : â„•), layer net m â‰¤ layer net n â†’ (m âˆˆ A â†” m âˆˆ B))
--   intro hâ‚‚

--   convert hâ‚‚ using 5
--   rename_i i
--   generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
--   sorry
  -- -- Just go in and subsitute m âˆˆ A for m âˆˆ B.
  -- intro (hâ‚ : âˆ€ (m : â„•), layer net m â‰¤ layer net n â†’ (m âˆˆ A â†” m âˆˆ B))
  -- intro hâ‚‚
  
  -- simp
  -- simp at hâ‚‚
  -- convert hâ‚‚ using 5
  -- rename_i i
  -- generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
  -- -- generalize hLm : layer net m = Lm

  -- have hâ‚ƒ : m âˆˆ preds net n := by
  --   rw [symm hm]
  --   simp [preds]
  --   exact get!_mem (predecessors net.toNet.graph n).data i
  -- have hâ‚„ : layer net m â‰¤ layer net n := by
  --   apply le_of_lt
  --   exact preds_decreasing net m n hâ‚ƒ
  -- exact (symm (hâ‚ m hâ‚„).to_eq).to_iff

/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Properties of Propagation
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

--------------------------------------------------------------------
lemma prop_layer_zero (net : BFNN) : âˆ€ (S : Set â„•) (n : â„•),
  layer net n = 0
  â†’ n âˆˆ propagate net S
  â†’ n âˆˆ S := by
--------------------------------------------------------------------
  sorry

--------------------------------------------------------------------
theorem propagate_is_extens : 
  âˆ€ (S : Set â„•),
  S âŠ† propagate net S := by
--------------------------------------------------------------------
  intro (S : Set â„•)
        (n : â„•) (hâ‚ : n âˆˆ S)
  simp only [Membership.mem, Set.Mem, propagate]

  -- By induction on the layer of the net containing n
  generalize hL : layer net n = L
  induction L

  -- Base Step
  case zero => 
    simp only [propagate_acc]
    exact hâ‚
  
  -- Inductive Step
  case succ k IH => 
    simp only [propagate_acc]
    exact Or.inl hâ‚

-- Corollary: The same statement, but for propagate_acc
-- (this is a helper lemma for the properties that follow.)
-------------------------------------------------
lemma propagate_acc_is_extens :
  âˆ€ (S : Set â„•),
  n âˆˆ S â†’ propagate_acc net S n (layer net n) := by
-------------------------------------------------
  intro (S : Set â„•)
  intro (hâ‚ : n âˆˆ S)
  have hâ‚‚ : n âˆˆ propagate net S := propagate_is_extens _ _ hâ‚
  simp only [Membership.mem, Set.Mem, propagate] at hâ‚‚
  exact hâ‚‚
  

--------------------------------------------------------------------
theorem propagate_is_idempotent : 
  âˆ€ (S : Set â„•),
  propagate net S = 
    propagate net (propagate net S) := by
--------------------------------------------------------------------
  intro (S : Set â„•)
  apply ext
  intro (n : â„•)
  simp only [Membership.mem, Set.Mem, propagate]

  -- By strong induction on the layer of the net containing n
  generalize hL : layer net n = L
  induction L using Nat.case_strong_induction_on generalizing n

  -- Base Step
  case hz =>
    simp only [Membership.mem, Set.Mem, propagate_acc]
    conv in (layer net n) => rw [hL]
    simp only [propagate_acc]
    exact âŸ¨fun x => x, fun x => xâŸ©
  
  -- Inductive Step
  case hi k IH =>
    apply Iff.intro
    
    -- Forward direction is easy, just apply extensive
    case mp =>
      intro hâ‚
      rw [symm hL]
      rw [symm hL] at hâ‚
      exact @propagate_acc_is_extens net _ _ hâ‚

    -- Backwards direction is trickier
    case mpr => 
      intro hâ‚
      
      -- By cases; either n âˆˆ S or n âˆ‰ S
      -- Again; either n âˆˆ propagate S or n âˆ‰ propagate S 
      by_cases n âˆˆ S
      case pos => 
        rw [symm hL]
        exact @propagate_acc_is_extens net _ _ h
      case neg => 
        by_cases propagate_acc net S n (layer net n)
        case pos => 
          rw [symm hL]
          exact h
        case neg =>
          -- Just some simplifications and rewriting definitions
          rename_i n_not_in_S
          rw [simp_propagate_acc net n_not_in_S]
          
          have hâ‚‚ : Â¬n âˆˆ propagate net S := h
          simp [propagate] at hâ‚‚
          rw [simp_propagate_acc net hâ‚‚] at hâ‚
          
          -- -- activ_agrees lemma goes here
          -- TODO: Having lots of trouble with the activ_agrees lemma atm...
          
          simp
          simp at hâ‚
          convert hâ‚ using 5
          rename_i i
          generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
          generalize hLm : layer net m = Lm

          -- Apply the inductive hypothesis!
          have hâ‚ƒ : m âˆˆ preds net n := by
            rw [symm hm]
            simp [preds]
            exact get!_mem (predecessors net.toNet.graph n).data i
          have hâ‚„ : Lm â‰¤ k := by
            rw [symm hLm]
            apply Nat.lt_succ.mp
            rw [symm hL]
            exact preds_decreasing net m n hâ‚ƒ
          exact IH Lm hâ‚„ m hLm
          


-- This is essentially Hannes' proof.
--------------------------------------------------------------------
theorem propagate_is_cumulative :
  âˆ€ (A B : Set â„•), A âŠ† B
  â†’ B âŠ† propagate net A
  â†’ propagate net A = propagate net B := by
--------------------------------------------------------------------
  intro (A : Set â„•) (B : Set â„•)
        (hâ‚ : A âŠ† B)
        (hâ‚‚ : B âŠ† propagate net A)
  apply ext
  intro (n : â„•)
  simp only [Membership.mem, Set.Mem, propagate]
  simp only [Membership.mem, Set.Mem, propagate] at hâ‚‚

  -- By induction on the layer of the net containing n
  generalize hL : layer net n = L
  induction L using Nat.case_strong_induction_on generalizing n

  -- Base Step
  case hz =>
    simp only [propagate_acc]
    apply Iff.intro
    case mp => exact fun hâ‚ƒ => hâ‚ hâ‚ƒ
    case mpr =>
      intro hâ‚ƒ
      have hâ‚„ : propagate_acc net A n (layer net n) := hâ‚‚ hâ‚ƒ
      conv at hâ‚„ in (layer net n) => rw [hL]
      simp only [propagate_acc] at hâ‚„
      exact hâ‚„

  -- Inductive Step
  case hi k IH => 
    apply Iff.intro

    -- Forward Direction
    case mp => 
      intro hâ‚ƒ

      -- By cases; either n âˆˆ B or n âˆ‰ B.
      -- Similarly, either n âˆˆ A or n âˆ‰ A. 
      by_cases n âˆˆ B
      case pos =>
        rw [symm hL]
        exact @propagate_acc_is_extens net _ _ h -- TODO: replace acc variation
      case neg =>
        by_cases n âˆˆ A
        case pos => 
          rename_i n_not_in_B 
          exact absurd (hâ‚ h) n_not_in_B
        case neg => 
          -- Just some simplifications and rewriting definitions
          rename_i n_not_in_B
          rw [simp_propagate_acc net h] at hâ‚ƒ
          rw [simp_propagate_acc net n_not_in_B]

          -- Just try to prove it and turn it into an 'activ_agree'
          -- lemma later!
          -- Go into 'prev_activ' and substitute using our IH.
          -- Then try to prove what's left.
          simp
          simp at hâ‚ƒ
          convert hâ‚ƒ using 5
          rename_i i
          generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
          generalize hLm : layer net m = Lm

          -- Apply the inductive hypothesis!
          have hâ‚ƒ : m âˆˆ preds net n := by
            rw [symm hm]
            simp [preds]
            exact get!_mem (predecessors net.toNet.graph n).data i
          have hâ‚„ : Lm â‰¤ k := by 
            rw [symm hLm]
            apply Nat.lt_succ.mp
            rw [symm hL]
            exact preds_decreasing net m n hâ‚ƒ
          exact (symm (IH Lm hâ‚„ m hLm).to_eq).to_iff

    -- Backwards Direction (should be very similar)
    case mpr => 
      intro hâ‚ƒ

      -- By cases; either n âˆˆ A or n âˆ‰ A
      by_cases n âˆˆ A
      case pos => 
        rw [symm hL]
        exact @propagate_acc_is_extens net _ _ h -- TODO: replace acc variation
      case neg => 
        by_cases n âˆˆ B
        case pos => 
          rename_i n_not_in_A
          rw [symm hL]
          exact hâ‚‚ h
        case neg => 
          -- Just some simplifications and rewriting definitions
          rename_i n_not_in_A
          rw [simp_propagate_acc net h] at hâ‚ƒ
          rw [simp_propagate_acc net n_not_in_A]

          -- Just try to prove it and turn it into an 'activ_agree'
          -- lemma later!
          -- Go into 'prev_activ' and substitute using our IH.
          -- Then try to prove what's left.
          simp
          simp at hâ‚ƒ
          convert hâ‚ƒ using 5
          rename_i i
          generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
          generalize hLm : layer net m = Lm

          -- Apply the inductive hypothesis!
          have hâ‚ƒ : m âˆˆ preds net n := by
            rw [symm hm]
            simp [preds]
            exact get!_mem (predecessors net.toNet.graph n).data i
          have hâ‚„ : Lm â‰¤ k := by 
            rw [symm hLm]
            apply Nat.lt_succ.mp
            rw [symm hL]
            exact preds_decreasing net m n hâ‚ƒ
          exact IH Lm hâ‚„ m hLm


-- #check propagate myBFNN {n : â„• | n â‰¤ 4}
-- #eval propagate myBFNN {n : â„• | n â‰¤ 4}
-- need to make sets finite in order to evaluate???
-- 
-- It's important for everything to be evaluatable, since:
-- 1) I will want to verify that a *specific*
--    neural network has certain properties
-- 2) #eval helps me debug errors

/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Properties of Graph-reachability
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- def reachable (net : BFNN) (S : Set â„•) : Set â„• :=
--   fun (n : â„•) =>
--     âˆƒ (m : â„•), (m âˆˆ S âˆ§ net.graph.hasPath m n)

-- -- hL: layer net n = 0
-- -- hâ‚: n âˆˆ B âˆ¨ n âˆˆ A âˆ§ reachable net B n
-- -- âŠ¢ n âˆˆ B

-- -- Argument: If there is a path from S to n, but n is in
-- -- layer 0 -- there are *no* incoming nodes, so the path
-- -- must be of length 0.  So n must be that n âˆˆ S with
-- -- a path to n, i.e. n âˆˆ S.
-- --------------------------------------------------------------------
-- lemma reach_layer_zero (net : BFNN) : âˆ€ (S : Set â„•) (n : â„•),
--   layer net n = 0
--   â†’ n âˆˆ reachable net S
--   â†’ n âˆˆ S := by
-- --------------------------------------------------------------------
--   sorry

-- --------------------------------------------------------------------
-- theorem reach_is_extens (net : BFNN) : âˆ€ (S : Set â„•),
--   S âŠ† reachable net S := by
-- --------------------------------------------------------------------
--   intro (S : Set â„•)
--         (n : â„•) (hâ‚ : n âˆˆ S)

--   have (hâ‚‚ : hasPath net.toNet.graph n n) := hasPath.trivial
--   exact âŸ¨n, âŸ¨hâ‚, hâ‚‚âŸ©âŸ©
  
-- --------------------------------------------------------------------
-- theorem reach_is_idempotent (net : BFNN) : âˆ€ (S : Set â„•),
--   reachable net S = reachable net (reachable net S) := by
-- --------------------------------------------------------------------
--   intro (S : Set â„•)
  
--   exact Set.ext (fun (n : â„•) =>
--     -- âŠ† direction (the easy direction; just apply 'extensive')
--     âŸ¨(fun (hâ‚ : n âˆˆ reachable net S) => 
--       let S_reach := reachable net S
--       reach_is_extens net S_reach hâ‚),

--     -- âŠ‡ direction
--     (fun (hâ‚ : n âˆˆ reachable net (reachable net S)) =>
--       match hâ‚ with
--       | âŸ¨x, hâ‚‚âŸ© => 
--         match hâ‚‚.1 with
--         | âŸ¨m, hâ‚ƒâŸ© =>
--           have (hâ‚„ : hasPath net.graph m n) := 
--             hasPath_trans net.graph hâ‚ƒ.2 hâ‚‚.2
--           âŸ¨m, âŸ¨hâ‚ƒ.1, hâ‚„âŸ©âŸ©)âŸ©)

-- --------------------------------------------------------------------
-- theorem reach_is_monotone (net : BFNN) : âˆ€ (A B : Set â„•),
--   A âŠ† B â†’ reachable net A âŠ† reachable net B := by
-- --------------------------------------------------------------------
--   intro (A : Set â„•) (B : Set â„•)
--         (hâ‚ : A âŠ† B)
--         (n : â„•) (hâ‚‚ : n âˆˆ reachable net A)

--   exact match hâ‚‚ with
--     | âŸ¨m, hâ‚ƒâŸ© => âŸ¨m, âŸ¨hâ‚ hâ‚ƒ.1, hâ‚ƒ.2âŸ©âŸ© 


/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Properties of Reverse Graph-reachability ("reached by")
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- def reachedby (net : BFNN) (S : Set â„•) : Set â„• :=
--   fun (m : â„•) =>
--     âˆƒ (n : â„•), (n âˆˆ S âˆ§ net.graph.hasPath m n)

-- --------------------------------------------------------------------
-- theorem reachedby_is_extens (net : BFNN) : âˆ€ (S : Set â„•),
--   S âŠ† reachedby net S := by
-- --------------------------------------------------------------------
--   intro (S : Set â„•)
--         (n : â„•) (hâ‚ : n âˆˆ S)

--   have (hâ‚‚ : hasPath net.toNet.graph n n) := hasPath.trivial
--   exact âŸ¨n, âŸ¨hâ‚, hâ‚‚âŸ©âŸ©
  
-- --------------------------------------------------------------------
-- theorem reachedby_is_idempotent (net : BFNN) : âˆ€ (S : Set â„•),
--   reachedby net S = reachedby net (reachedby net S) := by
-- --------------------------------------------------------------------
--   intro (S : Set â„•)
--   apply ext
--   intro (m : â„•)
--   apply Iff.intro

--   -- Forward direction (easy; just apply Extensive)
--   case mp => 
--     exact fun hâ‚ => reachedby_is_extens net (reachedby net S) hâ‚

--   -- Backwards direction
--   case mpr => 
--     intro (hâ‚ : m âˆˆ reachedby net (reachedby net S))
--     match hâ‚ with
--     | âŸ¨x, hâ‚‚âŸ© => 
--       match hâ‚‚.1 with
--       | âŸ¨n, hâ‚ƒâŸ© => 
--         exact âŸ¨n, âŸ¨hâ‚ƒ.1, hasPath_trans _ hâ‚‚.2 hâ‚ƒ.2âŸ©âŸ©

-- --------------------------------------------------------------------
-- theorem reachedby_is_monotone (net : BFNN) : âˆ€ (A B : Set â„•),
--   A âŠ† B â†’ reachedby net A âŠ† reachedby net B := by
-- --------------------------------------------------------------------
--   intro (A : Set â„•) (B : Set â„•)
--         (hâ‚ : A âŠ† B)
--         (n : â„•) (hâ‚‚ : n âˆˆ reachedby net A)

--   exact match hâ‚‚ with
--   | âŸ¨n, hâ‚ƒâŸ© => âŸ¨n, âŸ¨hâ‚ hâ‚ƒ.1, hâ‚ƒ.2âŸ©âŸ©  


/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Conditional Graph Reachability
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/



-- A focused path is a path where every node is contained
-- within the set S.
inductive focusedPath (g : Graph â„• Î²) (S : Set â„•) : â„• â†’ â„• â†’ Prop where
  | trivial {u : â„•} :
      u âˆˆ S â†’ focusedPath g S u u
  | from_path {u v w : â„•} : 
      focusedPath g S u v â†’ hasEdge g v w â†’ w âˆˆ S â†’ focusedPath g S u w


-- Updated version!
-- This is the set of all nodes reachable from B using
-- paths where *every* node in the path is within A
-- (including the initial and final nodes)
def reachable (net : BFNN) (A B : Set â„•) : Set â„• :=
  fun (n : â„•) =>
    -- This is the actual definition, I got it wrong before
    âˆƒ (m : â„•), m âˆˆ B âˆ§ focusedPath net.graph A m n

-- Argument: If there is a path from B to n, but n is in
-- layer 0 -- there are *no* incoming nodes -- then the path
-- must be of length 0.  So n must be that n âˆˆ B with
-- a path to n, i.e. n âˆˆ B.
--------------------------------------------------------------------
lemma reach_layer_zero (net : BFNN) : âˆ€ (A B : Set â„•) (n : â„•),
  layer net n = 0
  â†’ n âˆˆ reachable net A B
  â†’ n âˆˆ B := by
--------------------------------------------------------------------
  sorry


--------------------------------------------------------------------
theorem reach_is_monotone (net : BFNN) : âˆ€ (S A B : Set â„•),
  A âŠ† B â†’ reachable net S A âŠ† reachable net S B := by
--------------------------------------------------------------------
  intro (S : Set â„•)
        (A : Set â„•)
        (B : Set â„•)
        (hâ‚ : A âŠ† B)
        (n : â„•) (hâ‚‚ : n âˆˆ reachable net S A)
  
  exact match hâ‚‚ with
    | âŸ¨m, hmâŸ© => âŸ¨m, âŸ¨hâ‚ hm.1, hm.2âŸ©âŸ©

-- --------------------------------------------------------------------
-- theorem reach_within (net : BFNN) : âˆ€ (A B : Set â„•),
--   reachable net A B âŠ† A := by
-- --------------------------------------------------------------------
--   sorry

-- TODO: Prove stuff about reachable.
-- It looks like
-- reachable A B âŠ† A,
-- but I'm not sure about the complete rules surrounding it.
-- 
-- NOTE:
-- Van Benthem describes "conditional common knowledge" as
-- CG(A, B) "is true in all worlds reachable via some finite path
-- of accessibilities running entirely through worlds satisfying A"
-- [Van Benthem, Belief Revision and Dynamic Logic, page 6]
-- 
-- This is *exactly* what reachable is doing!!!
-- In this paper, he also talks about "pre-encoding" future
-- information in order to get a reduction, which is exactly
-- what we're doing here!

--------------------------------------------------------------------
theorem reach_subset (net : BFNN) : âˆ€ (A B : Set â„•),
  reachable net A B âŠ† A := by
--------------------------------------------------------------------
  sorry


/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Reach-Prop Interaction Properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- --------------------------------------------------------------------
-- theorem propagate_reach_inclusion (net : BFNN) : âˆ€ (S : Set â„•),
--   propagate net S âŠ† reachable net S := by
-- --------------------------------------------------------------------
--   sorry

-- --------------------------------------------------------------------
-- lemma minimal_cause_helper (net : BFNN) : âˆ€ (A B : Set â„•), âˆ€ (n : â„•),
--   n âˆˆ reachedby net B
--   â†’ (n âˆˆ propagate net A
--   â†” n âˆˆ propagate net (A âˆ© reachedby net B)) := by
-- --------------------------------------------------------------------
--   intro (A : Set â„•) (B : Set â„•)
--   intro (n : â„•)
--   intro (hâ‚ : n âˆˆ reachedby net B)
--   simp only [Membership.mem, Set.Mem, propagate]

--   -- By induction on the layer of the net containing n
--   generalize hL : layer net n = L
--   induction L using Nat.case_strong_induction_on generalizing n
  
--   -- Base Step
--   case hz => 
--     apply Iff.intro
--     case mp => 
--       intro hâ‚‚
--       simp only [propagate_acc]
--       simp only [propagate_acc] at hâ‚‚
--       exact âŸ¨hâ‚‚, hâ‚âŸ©

--     case mpr => 
--       intro hâ‚‚
--       simp only [propagate_acc]
--       simp only [propagate_acc] at hâ‚‚
--       exact hâ‚‚.1

--   -- Inductive Step
--   case hi k IH => 
--     apply Iff.intro

--     -- Forward Direction
--     case mp => 
--       intro hâ‚‚

--       -- By cases; either n âˆˆ A or not.
--       by_cases n âˆˆ A
--       case pos => 
--         -- This case is trivial (just apply Extens)
--         rw [symm hL]
--         have hâ‚ƒ : n âˆˆ A âˆ© reachedby net B := âŸ¨h, hâ‚âŸ© 
--         exact @propagate_acc_is_extens net _ _ hâ‚ƒ
--       case neg => 
--         -- If n âˆ‰ A, then n âˆ‰ A âˆ© reachedby net B
--         have hâ‚ƒ : n âˆ‰ A âˆ© reachedby net B := 
--           fun n_in_A => absurd n_in_A.1 h
        
--         -- Just some simplifications and rewriting definitions
--         rw [simp_propagate_acc net h] at hâ‚‚
--         rw [simp_propagate_acc net hâ‚ƒ]

--         -- TODO: This is the stuff that should go in the activ_agree lemma!
--         simp
--         simp at hâ‚‚
--         convert hâ‚‚ using 5
--         rename_i i
--         generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
--         generalize hLm : layer net m = Lm

--         -- Apply the inductive hypothesis!
--         have hâ‚„ : m âˆˆ preds net n := by
--           rw [symm hm]
--           simp [preds]
--           exact get!_mem (predecessors net.toNet.graph n).data i
--         have hâ‚… : Lm â‰¤ k := by
--           rw [symm hLm]
--           apply Nat.lt_succ.mp
--           rw [symm hL]
--           exact preds_decreasing net m n hâ‚„
--         have hâ‚† : m âˆˆ reachedby net B :=
--           match hâ‚ with
--           | âŸ¨x, hxâŸ© => âŸ¨x, âŸ¨hx.1, hasPath_trans _ (preds_path _ hâ‚„) hx.2âŸ©âŸ©
--         exact (symm (IH Lm hâ‚… m hâ‚† hLm).to_eq).to_iff

--     -- Backwards Direction (should be similar)
--     case mpr =>
--       intro hâ‚‚

--       -- By cases; either n âˆˆ A or not.
--       by_cases n âˆˆ A
--       case pos => 
--         -- This case is trivial (just apply Extens)
--         rw [symm hL]
--         exact @propagate_acc_is_extens net _ _ h
--       case neg => 
--         -- If n âˆ‰ A, then n âˆ‰ A âˆ© reachedby net B
--         have hâ‚ƒ : n âˆ‰ A âˆ© reachedby net B := 
--           fun n_in_A => absurd n_in_A.1 h
        
--         -- Just some simplifications and rewriting definitions
--         rw [simp_propagate_acc net hâ‚ƒ] at hâ‚‚
--         rw [simp_propagate_acc net h]

--         -- TODO: This is the stuff that should go in the activ_agree lemma!
--         simp
--         simp at hâ‚‚
--         convert hâ‚‚ using 5
--         rename_i i
--         generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
--         generalize hLm : layer net m = Lm

--         -- Apply the inductive hypothesis!
--         have hâ‚„ : m âˆˆ preds net n := by
--           rw [symm hm]
--           simp [preds]
--           exact get!_mem (predecessors net.toNet.graph n).data i
--         have hâ‚… : Lm â‰¤ k := by
--           rw [symm hLm]
--           apply Nat.lt_succ.mp
--           rw [symm hL]
--           exact preds_decreasing net m n hâ‚„
--         have hâ‚† : m âˆˆ reachedby net B :=
--           match hâ‚ with
--           | âŸ¨x, hxâŸ© => âŸ¨x, âŸ¨hx.1, hasPath_trans _ (preds_path _ hâ‚„) hx.2âŸ©âŸ©
--         exact IH Lm hâ‚… m hâ‚† hLm


-- -- This is the actual property I want, re-written with conditionals
-- -- in mind
-- --------------------------------------------------------------------
-- theorem minimal_cause (net : BFNN) : âˆ€ (A B : Set â„•),
--   B âŠ† propagate net A
--   â†” B âŠ† propagate net (A âˆ© reachedby net B) := by
-- --------------------------------------------------------------------
--   intro (A : Set â„•) (B : Set â„•)
--   apply Iff.intro
--   case mp => exact fun hâ‚ n hâ‚‚ => (minimal_cause_helper net _ _ _ 
--     (reachedby_is_extens _ _ hâ‚‚)).mp (hâ‚ hâ‚‚)
--   case mpr => exact fun hâ‚ n hâ‚‚ => (minimal_cause_helper net _ _ _ 
--     (reachedby_is_extens _ _ hâ‚‚)).mpr (hâ‚ hâ‚‚)

/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Update Policy: "Make neurons fire together"
  (without regard for the edges of the net)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

/-
*Notes*
The basic idea is that we take a subset A of the graph, and
increase our preference for nodes in A as much as possible.
We do this by: 1) completing the graph A, and 2) maximizing all
of the edges within this completed graph.  The overall effect
is that for all neurons m, n âˆˆ A, m fires exactly when n fires.

But this operation results in a graph with cycles -- so [A] Prop(B)
is not well-defined!  But we can do something equivalent:
Take all the nodes in A, and quotient them.  This results in a
net where all the nodes m, n âˆˆ A "fire as one".

So we need:
  [Def] Define 'complete_and_max' update
  [Def] Define 'fire_together' update (the quotient structure)
  [Thm] Prove that the two updates are equivalent.
        (We can't use Prop for this -- maybe I can prove
         that the 'activ' for both nets agrees?)
  [Thm] Find a reduction for 'fire_together' and prove it.
        (It should look like the dual of Lexicographic Upgrade)
  [Cor] 'fire_together' is the dual of Lexicographic Upgrade
    [Depends] 
      Preference Models
      Lexicographic Upgrade
      Lexicographic Upgrade reduction
      Model translation from pref models âŸ· nets
-/

-- def complete_and_max (net : BFNN) (A : Set â„•) : BFNN :=
--   sorry

-- def fire_together (net : BFNN) (A : Set â„•) : BFNN :=
-- { net with
--   graph := sorry
--   activation := sorry
--   rate := sorry

--   -- binary := sorry
--   binary := sorry
--   acyclic := sorry
--   activ_nondecr := sorry
--   activ_pos := sorry
-- }



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Naive (Unstable) Hebbian Update
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- Increase the weight on the given edge xâ‚ âŸ¶ xâ‚‚  by
-- Î· * act(xâ‚) * act(xâ‚‚), *only if* the nodes are both within
-- propagate net S.
noncomputable
def weight_update (net : BFNN) (S : Set â„•) 
  (xâ‚ : â„•) (edge : Edge Float) : Float := 
  let xâ‚‚ := edge.target
  let activâ‚ := if xâ‚ âˆˆ propagate net S then 1.0 else 0.0
  let activâ‚‚ := if xâ‚‚ âˆˆ propagate net S then 1.0 else 0.0
  edge.weight + (net.rate * activâ‚ * activâ‚‚)

noncomputable
def graph_update (net : BFNN) (g : Graph â„• Float) (S : Set â„•) : Graph â„• Float :=
  { vertices := Array.map (fun v => 
    { v with adjacencyList := Array.map (fun edge => 
      { edge with weight := weight_update net S v.payload edge}) v.adjacencyList}) g.vertices }

-- A single step of Hebbian update.
-- Propagate S through the net, and then increase the weights
-- of all the edges xâ‚ âŸ¶ xâ‚‚ involved in that propagation
-- by Î· * xâ‚ * xâ‚‚.
noncomputable
def hebb (net : BFNN) (S : Set â„•) : BFNN :=
{ net with
  graph := graph_update net net.graph S

  -- We have to ensure that the update doesn't create any cycles
  -- (In this case, we're only changing the weights.)
  acyclic := sorry
}


-- Takes a graph update function 'f' (e.g. graph_update for Hebb)
-- and iterates it 'no_times' times.
-- netáµ¢ and Sáµ¢ are the initial inputs.
def iterate (f : Graph â„• Float â†’ Set â„• â†’ Graph â„• Float) 
  (no_times : â„•) (gáµ¢ : Graph â„• Float) (Sáµ¢ : Set â„•) : Graph â„• Float :=
  match no_times with
  | Nat.zero => gáµ¢
  | Nat.succ k => f (iterate f k gáµ¢ Sáµ¢) Sáµ¢


-- We score neurons by the total sum of *negative* weights coming 
-- into them.  The neuron with the lowest score is the least likely
-- to activate (in the worst case where all of its negative signals
-- activate but none of its positive ones do).  If a neuron has
-- no negative incoming weights, we give it a score of 0.
def neg_weight_score (net : BFNN) (n : â„•) : Float :=
  sorry


-- This is the exact number of iterations of Hebbian learning
-- on 'net' and 'S' that we need to make the network unstable,
-- i.e. any activation involved within Prop(S) simply goes through.
-- 
-- This is the trickiest part to get right -- we actually need
-- to *construct* this number, based on the net's activation
-- function and the edge weights within Prop(S)!
-- 
-- We first pick the neuron with the lowest 'neg_weight_score' n_min.
-- The number of iterations is that number which would (in the worst
-- case) guarantee that n_min gets activated.
-- 
-- If n_score is n_min's score, and X is that point at which
-- our activation function is guranteed to be 1.0, and Î· is the
-- learning rate, then we return
-- 
-- (X - n_score) / Î·   *(I think!)*
def hebb_unstable_point (net : BFNN) (S : Set â„•) : â„• :=
  sorry
  -- let x := choose net.activ_pos
  -- have hâ‚ : net.activation x = 1.0 := sorry

  -- let n_min := @List.minimum (Vertex â„• Float) sorry sorry net.graph.vertices.toList
  -- let n_score := sorry
  -- sorry

-- Iterated hebbian update, up to a certain fixed point.
-- We implement this as a new net, whose graph is
-- 'graph_update' iterated 'hebb_unstable_point'
-- number of times.
-- FUTURE: Consider re-doing this using limits of graphs/categories
noncomputable
def hebb_star (net : BFNN) (S : Set â„•) : BFNN := 
{ net with
  graph := iterate (graph_update net) (hebb_unstable_point net S) net.graph S
  
  -- We have to ensure that the update doesn't create any cycles
  -- (In this case, we're only changing the weights.)
  acyclic := sorry
}



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Properties of Unstable Hebbian Update
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- A net netâ‚ is a subnet of netâ‚‚ (netâ‚ â‰¼ netâ‚‚) iff for all
-- sets S, every node activated in the propagation of S
-- in netâ‚ is activated in the propagation of S in netâ‚‚.
-- (They both have the same *propagation structure*)
def subnet (netâ‚ netâ‚‚ : BFNN) : Prop :=
  âˆ€ (S : Set â„•), propagate netâ‚ S âŠ† propagate netâ‚‚ S

infixl:65   " â‰¼ " => subnet


-- Two nets are equivalent if they have the same 
-- *propagation structure* (i.e. if their propagations agree 
-- for every set S)
def net_eq (netâ‚ netâ‚‚ : BFNN) : Prop :=
  netâ‚ â‰¼ netâ‚‚ âˆ§ netâ‚‚ â‰¼ netâ‚

infixl:65   " â‰¡ " => net_eq


-- A super easy example, just to briefly test â‰¼ and â‰¡
example : example_net â‰¡ example_net :=
  âŸ¨fun S n h => h, fun S n h => hâŸ©  


-- propagate_N (S) = propagate_hebb(N, S) (S)
-- This essentially says that repeated hebbian update
-- is well-defined; *after* updating on S, we can update
-- on S again and increase weights within the same propagation.
-- (The propagation of S doesn't suddenly change, which is
--  something we might be worried about.)
-- TODO: Not sure if I need this anymore!
-- It's somewhat interesting, but might not help with the
-- reduction.
-- --------------------------------------------------------------------
-- theorem hebb_iteration_is_well_defined (net : BFNN) (S : Set â„•) : 
--   propagate (hebb net S) S = propagate net S := by
-- --------------------------------------------------------------------
--   apply ext
--   intro (n : â„•)
--   simp only [Membership.mem, Set.Mem, propagate]

--   -- By induction on the layer of the net containing n
--   generalize hL : layer net n = L
--   induction L using Nat.case_strong_induction_on generalizing n

--   -- Base Step
--   case hz =>
--     apply Iff.intro
--     case mp => 
--       simp only [propagate_acc]
--       exact fun x => x
--     case mpr => 
--       simp only [propagate_acc]
--       exact fun x => x

--   -- Inductive Step
--   case hi k IH => 
--     apply Iff.intro

--     -- Forward Direction
--     case mp => 
--       intro hâ‚
--       simp only [propagate_acc] at hâ‚
--       simp only [propagate_acc]

--       cases hâ‚
--       case inl hâ‚‚ => exact Or.inl hâ‚‚
--       case inr hâ‚‚ =>
--         apply Or.inr

--         -- TODO: This is the stuff that should go in the activ_agree lemma!        
--         simp
--         simp at hâ‚‚
--         sorry
--         -- I do not have the tools to show this at this point.
--         -- I need a lemma about activations in the hebbian updated net.

--         -- show_term convert hâ‚‚

--     -- Backwards Direction
--     case mpr => sorry

-- This says that 'hebb_star' is a fixed point of 'hebb'
-- (with respect to â‰¡).  i.e. in the following sense, f(X) = X:
--   hebb(X, S) â‰¡ X,
-- where X = hebb_star net S
-- 
-- I may need additional lemmas (e.g. an activation function
-- within Prop(S) in hebb_star will simply go through.)
-- 
-- One important lemma:  If an edge is not in the propagation of S,
-- its weight is unaffected.
--------------------------------------------------------------------
theorem hebb_star_is_fixed_point (net : BFNN) (S : Set â„•) : 
  hebb (hebb_star net S) S â‰¡ hebb_star net S := by 
--------------------------------------------------------------------
  sorry



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Properties of Naive Hebbian Update
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- Hebbian update hebb_star does not affect the predecessors
-- of any node.
--------------------------------------------------------------------
theorem hebb_preds (net : BFNN) (S : Set â„•) : 
  preds (hebb_star net S) n = preds net n := by
--------------------------------------------------------------------
  sorry


-- Hebbian update hebb_star does not affect which neurons are
-- on which layer of the net.
--------------------------------------------------------------------
theorem hebb_layers (net : BFNN) (S : Set â„•) : 
  layer (hebb_star net S) n = layer net n := by
--------------------------------------------------------------------
  exact rfl


-- Hebbian update hebb_star does not affect the activation function.
--------------------------------------------------------------------
theorem hebb_activation (net : BFNN) (S : Set â„•) : 
  (hebb_star net S).activation = net.activation := by 
--------------------------------------------------------------------
  exact rfl


-- Hebbian update hebb_star does not affect graph reachability
-- (It only affects the edge weights)
--------------------------------------------------------------------
theorem hebb_reach (net : BFNN) (A B : Set â„•) : 
  reachable (hebb_star net A) B = 
    reachable net B := by 
--------------------------------------------------------------------
  sorry
  
  
-- Every net N is a subnet of (hebb_star N)
-- (i.e. hebb_star includes the previous propagations)
-- (We had this property in The Logic of Hebbian Learning)
--------------------------------------------------------------------
theorem hebb_extensive (net : BFNN) (A : Set â„•) : 
  net â‰¼ (hebb_star net A) := by 
--------------------------------------------------------------------
  intro (B : Set â„•)
  intro (n : â„•)
  intro (hâ‚ : n âˆˆ propagate net B)
  simp only [Membership.mem, Set.Mem, propagate]
  simp only [Membership.mem, Set.Mem, propagate] at hâ‚
  
  -- By induction on the layer of the 
  generalize hL : layer net n = L
  induction L

  --------------------------------
  -- Base Step
  --------------------------------
  case zero => 
    rw [hL] at hâ‚
    simp only [propagate_acc]
    simp only [propagate_acc] at hâ‚
    exact hâ‚

  --------------------------------
  -- Inductive Step
  --------------------------------
  case succ k IH => 
    -- By cases, to later simplify propagate_acc
    by_cases n âˆˆ B
    case pos => 
      rw [â† hL]
      rw [â† hebb_layers net A]
      exact propagate_acc_is_extens _ _ h  
    
    case neg => 
      -- Do simplifications and rewriting
      rw [hL] at hâ‚
      rw [simp_propagate_acc _ h]
      rw [simp_propagate_acc _ h] at hâ‚

      sorry -- need to argue here that 'activ' is *nondecreasing*
            -- i.e. never decreases a weight.


--------------------------------------------------------------------
lemma hebb_acc_is_extens (net : BFNN) (A B : Set â„•) (n : â„•) :
  propagate_acc net B n (layer net n) â†’ 
  propagate_acc (hebb_star net A) B n (layer net n) := by
-------------------------------------------------------------------- 
  intro hâ‚
  have hâ‚‚ : n âˆˆ propagate (hebb_star net A) B := hebb_extensive _ _ _ hâ‚
  simp only [Membership.mem, Set.Mem, propagate] at hâ‚‚
  exact hâ‚‚



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  The more interesting/crucial properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- If n âˆ‰ Prop(A), then the weights in the updated net are the same
-- as the weights in the original net.
--------------------------------------------------------------------
theorem hebb_weightsâ‚ (net : BFNN) : 
  n âˆ‰ propagate net A
  â†’ âˆ€ (i : â„•),
    (getEdgeWeight (hebb_star net A).toNet.graph ((preds net n).get! i) n =
    getEdgeWeight net.toNet.graph ((preds net n).get! i) n) := by
--------------------------------------------------------------------
  sorry


-- If all predecessors of n âˆ‰ Prop(A), then the weights in the 
-- updated net are the same as the weights in the original net.
--------------------------------------------------------------------
theorem hebb_weightsâ‚‚ (net : BFNN) : 
  (âˆ€ x, x âˆˆ preds net n â†’ x âˆ‰ propagate net A)
  â†’ âˆ€ (i : â„•),
    (getEdgeWeight (hebb_star net A).toNet.graph ((preds net n).get! i) n =
    getEdgeWeight net.toNet.graph ((preds net n).get! i) n) := by
--------------------------------------------------------------------
  sorry


-- If n âˆ‰ Prop(A), then activ (hebb_star net A) _ n = activ net _ n.
--------------------------------------------------------------------
theorem hebb_activâ‚ (net : BFNN) (A : Set â„•) (prev_activ : List Float) :
  n âˆ‰ propagate net A
  â†’ activ (hebb_star net A) prev_activ n = activ net prev_activ n := by
--------------------------------------------------------------------
  intro hâ‚
  simp only [activ]
  rw [hebb_activation net A]
  rw [hebb_preds net A]
  conv =>
    lhs; enter [1, 2, 1, 2, i, 1]
    rw [hebb_weightsâ‚ _ hâ‚]


-- If every predecessor of n âˆ‰ Prop(A), then
-- activ (hebb_star net A) _ n = activ net _ n.
--------------------------------------------------------------------
theorem hebb_activâ‚‚ (net : BFNN) (A : Set â„•) (prev_activ : List Float) :
  (âˆ€ x, x âˆˆ preds net n â†’ x âˆ‰ propagate net A)
  â†’ activ (hebb_star net A) prev_activ n = activ net prev_activ n := by
--------------------------------------------------------------------
  intro hâ‚
  simp only [activ]
  rw [hebb_activation net A]
  rw [hebb_preds net A]
  conv =>
    lhs; enter [1, 2, 1, 2, i, 1]
    rw [hebb_weightsâ‚‚ _ hâ‚]


-- If there is a path within Prop(A) from B to n, then, since this
-- path is updated in hebb_star, n âˆˆ Prop(B).
--------------------------------------------------------------------
theorem hebb_updated_path (net : BFNN) (A B : Set â„•) :
  reachable net (propagate net A) (propagate net B)
  âŠ† propagate (hebb_star net A) B := by
--------------------------------------------------------------------
  intro (n : â„•)
  intro hâ‚
  
  -- We have a path from Prop(B) to n, going through Prop(A).
  match hâ‚ with
  | âŸ¨m, hmâŸ© => 

    -- By induction on the length of this path
    induction hm.2
    case trivial path_mm => exact hebb_extensive _ _ _ hm.1
    case from_path v w path_mv edge_vw w_in_propA IH => 
      -- This edge from v to w is key;
      -- Got to go inside hebb_star to see what it's updating.
      sorry


/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Reduction for Unstable Hebbian Update
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/

-- These two are the big theorems.
-- They explain what hebb_star learns in terms of what the net
-- believed *before* update -- it turns out that we can completely
-- reduce the dynamic behavior to the static behavior.
--------------------------------------------------------------------
theorem hebb_reduction_empty (net : BFNN) (A B : Set â„•) : 
  propagate net A âˆ© propagate net B = âˆ… â†’

  propagate (hebb_star net A) B = propagate net B := by 
--------------------------------------------------------------------
  intro h_empty
  apply ext
  intro (n : â„•)

  -- By induction on the layer of the net containing n
  generalize hL : layer net n = L
  induction L using Nat.case_strong_induction_on generalizing n

  --------------------------------
  -- Base Step
  --------------------------------
  -- Easy; after simplifying, show that B = B.
  case hz => 
    simp only [Membership.mem, Set.Mem, propagate]
    rw [hebb_layers net A]
    rw [hL]
    simp only [propagate_acc]

  --------------------------------
  -- Inductive Step
  --------------------------------
  case hi L IH => 
    -- Backwards direction is easy;
    -- As for forward direction, TODO
    apply Iff.intro
    case mpr => exact fun hâ‚ => hebb_extensive _ _ _ hâ‚
    case mp =>
      -- Split by whether n âˆˆ B, in order to simplify propagate_acc
      by_cases n âˆˆ B
      case pos => exact fun hâ‚ => propagate_is_extens _ _ h
      case neg => 
        intro hâ‚

        -- From here, we split *again*, depending on whether n âˆˆ Prop(A).
        by_cases n âˆˆ propagate net A

        ---------------------
        -- Case 1: n âˆˆ Prop(A)
        ---------------------
        case pos => sorry

        ---------------------
        -- Case 1: n âˆ‰ Prop(A)
        ---------------------
        case neg => sorry


  -- -- Backwards direction is easy;
  -- -- As for forward direction, TODO
  -- apply Iff.intro
  -- case mpr => exact fun hâ‚ => hebb_extensive _ _ _ hâ‚
  -- case mp => 
  --   intro hâ‚
  --   sorry -- need to do induction!!!  (still easier than the big reduction)


--------------------------------------------------------------------
theorem hebb_reduction_nonempty (net : BFNN) (A B : Set â„•) : 
  propagate net A âˆ© propagate net B â‰  âˆ… â†’

  propagate (hebb_star net A) B =
  propagate net (B âˆª reachable net (propagate net A) (propagate net B)) := by 
--------------------------------------------------------------------
  intro h_nonempty
  apply ext
  intro (n : â„•)
  simp only [Membership.mem, Set.Mem, propagate]
  
  -- By induction on the layer of the net containing n
  generalize hL : layer (hebb_star net A) n = L
  induction L using Nat.case_strong_induction_on generalizing n

  --------------------------------
  -- Base Step
  --------------------------------
  case hz => 
    -- First, do the base case simplifications
    simp only [propagate_acc]
    simp only [Union.union, Set.union, Membership.mem, Set.Mem, setOf]

    -- Forward direction is the easy part, so we do it first.
    -- Backwards direction relies on reach_layer_zero,
    -- a fact about paths when we know n is at layer 0.
    apply Iff.intro
    case mp => exact fun hâ‚ => Or.inl hâ‚
    case mpr => 
      intro hâ‚

      -- Either n âˆˆ B or n is reachable from Prop(B) using only
      -- paths within Prop(A).  At layer 0, this means n âˆˆ B.
      cases hâ‚
      case inl hâ‚‚ => exact hâ‚‚
      case inr hâ‚‚ => 
        have heq : layer net n = 0 := Eq.trans (symm (hebb_layers net A)) hL
        exact prop_layer_zero _ _ _ heq (reach_layer_zero _ _ _ _ heq hâ‚‚)

  --------------------------------
  -- Inductive Step
  --------------------------------
  case hi L IH => 
    apply Iff.intro
    
    ---------------------
    -- Backward Direction
    ---------------------
    case mpr =>
      intro hâ‚
      
      -- By cases; either n âˆˆ B âˆª Reach(Prop(A), Prop(B)), or not.
      by_cases n âˆˆ B âˆª reachable net (propagate net A) (propagate net B)
      case pos =>
        rw [â† hL]
        rw [hebb_layers]

        -- From here, we split again; either:
        --    1. n âˆˆ B, and by extens n âˆˆ Prop(B) in (hebb_star net)
        --    2. n âˆˆ Reach(Prop(A), Prop(B)).  In this case, this path
        --       has been updated in the (hebb_star net), so of course
        --       n âˆˆ Prop(B) in (hebb_star_net)
        --       i.e. apply [hebb_updated_path]! 
        cases h
        case inl hâ‚‚ => exact propagate_acc_is_extens _ _ hâ‚‚
        case inr hâ‚‚ =>
          have hâ‚ƒ : n âˆˆ propagate (hebb_star net A) B := 
            hebb_updated_path _ _ _ hâ‚‚
          simp only [propagate, Membership.mem, Set.Mem] at hâ‚ƒ
          exact hâ‚ƒ

      case neg hâ‚‚ =>
        -- From here, we split *again*, depending on whether n âˆˆ Prop(A).
        by_cases n âˆˆ propagate net A 

        ---------------------
        -- Case 1: n âˆˆ Prop(A)
        ---------------------
        case pos => 
          -- Since Prop(A) âˆ© Prop(B) is nonempty, there is an m
          -- in the intersection.
          have hâ‚ƒ : âˆƒ m, m âˆˆ propagate net A âˆ§ m âˆˆ propagate net B :=
            Set.inter_nonempty_iff_exists_left.mp
              (Set.nonempty_iff_ne_empty.mpr h_nonempty)

          match hâ‚ƒ with
          | âŸ¨m, hmâŸ© => 
            -- Moreover, we can assume this m is the *smallest* such
            -- m âˆˆ Prop(A)!  (Via the well-ordering principle)
            have hâ‚„ : âˆ€ x, x âˆˆ propagate net A â†’
              layer net m â‰¤ layer net x := by
              sorry
            
            cases eq_or_lt_of_le (hâ‚„ n h)
            
            ---------------------
            -- Case 1.1: n âˆˆ Prop(A)
            -- and layer[m] < layer[n]
            ---------------------
            -- In this case, since the net is transitively closed
            -- (fully connected), we have an edge from m âˆˆ Prop(A) âˆ© Prop(B)
            -- to n âˆˆ Prop(A).  This gives us n âˆˆ Reach(Prop(A), Prop(B)).
            case inr hâ‚… =>
              -- We just provide the path from mâŸ¶n.
              have hâ‚† : n âˆˆ reachable net (propagate net A) (propagate net B) := by
                exact âŸ¨m, âŸ¨hm.2, 
                  focusedPath.from_path (focusedPath.trivial hm.1) 
                    (connected _ m n hâ‚…) hâŸ©âŸ©

              -- In this case, we conclude that n âˆˆ Prop(B) in
              -- the updated net by 'hebb_updated_path'
              have hâ‚‡ : n âˆˆ propagate (hebb_star net A) B := by
                exact hebb_updated_path _ _ _ hâ‚†
              
              simp only [propagate, Membership.mem, Set.Mem] at hâ‚‡
              rw [â† hL]
              exact hâ‚‡

            ---------------------
            -- Case 1.2: n âˆˆ Prop(A)
            -- and layer[m] = layer[n]
            ---------------------
            -- In this case, the activ's are the same, so
            -- we can straightforwardly apply our inductive
            -- hypothesis.
            case inl hâ‚… =>
              -- First, we show that any predecessor of n
              -- cannot be in Prop(A).
              have hâ‚† : âˆ€ x, x âˆˆ preds net n â†’ x âˆ‰ propagate net A := by
                rw [hâ‚…] at hâ‚„
                exact fun x hx x_in_propA => 
                  absurd (hâ‚„ x x_in_propA) (not_le.mpr (preds_decreasing _ _ _ hx))

              -- We get ready to simplify propagate_acc
              rename_i n_not_in_reach
              have n_not_in_B : n âˆ‰ B :=
                fun n_in_B => absurd (Set.mem_union_left _ n_in_B) n_not_in_reach

              -- Simplifications and rewriting, to prepare for IH
              -- We also rewrite the 'preds', 'layers', and 'activ'
              -- for (hebb_star net) in terms of the original 'net'.
              simp only [propagate] at n_not_in_reach
              rw [simp_propagate_acc _ n_not_in_B]
              rw [simp_propagate_acc _ n_not_in_reach] at hâ‚
              
              -- TODO: Use hebb_activâ‚‚, which says that if all
              -- of the preds âˆ‰ Prop(A), the activ's are the same.
              rw [hebb_activâ‚‚ _ _ _ hâ‚†] -- rewrite 'activ'
              rw [hebb_preds net A] -- rewrite 'preds'
              conv => -- rewrite 'layers'
                enter [2, 2, i, m, 1]
                rw [hebb_layers net A]
              simp
              simp at hâ‚
              convert hâ‚ using 5
              rename_i i
              generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
              generalize hLm : layer net m = Lm
              
              -- We are now ready to apply our inductive hypothesis!
              have hâ‚‡ : m âˆˆ preds net n := by
                rw [symm hm]
                simp [preds]
                exact get!_mem (predecessors net.toNet.graph n).data i
              have hâ‚ˆ : Lm â‰¤ L := by
                rw [symm hLm]
                apply Nat.lt_succ.mp
                rw [symm hL]
                rw [hebb_layers net A]
                exact preds_decreasing net m n hâ‚‡
              exact IH Lm hâ‚ˆ m hLm

        ---------------------
        -- Case 2: n âˆ‰ Prop(A)
        ---------------------
        -- In this case, the activ's are the same, so we can
        -- straightforwardly apply our inductive hypothesis.
        case neg =>
          -- We get ready to simplify propagate_acc
          rename_i n_not_in_reach
          have n_not_in_B : n âˆ‰ B :=
            fun n_in_B => absurd (Set.mem_union_left _ n_in_B) n_not_in_reach

          -- Simplifications and rewriting, to prepare for IH
          -- We also rewrite the 'preds', 'layers', and 'activ'
          -- for (hebb_star net) in terms of the original 'net'.
          simp only [propagate] at n_not_in_reach
          rw [simp_propagate_acc _ n_not_in_B]
          rw [simp_propagate_acc _ n_not_in_reach] at hâ‚
          
          rw [hebb_activâ‚ _ _ _ h] -- rewrite 'activ'
          rw [hebb_preds net A] -- rewrite 'preds'
          conv => -- rewrite 'layers'
            enter [2, 2, i, m, 1]
            rw [hebb_layers net A]
          simp
          simp at hâ‚
          convert hâ‚ using 5
          rename_i i
          generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
          generalize hLm : layer net m = Lm
          
          -- We are now ready to apply our inductive hypothesis!
          have hâ‚‚ : m âˆˆ preds net n := by
            rw [symm hm]
            simp [preds]
            exact get!_mem (predecessors net.toNet.graph n).data i
          have hâ‚ƒ : Lm â‰¤ L := by
            rw [symm hLm]
            apply Nat.lt_succ.mp
            rw [symm hL]
            rw [hebb_layers net A]
            exact preds_decreasing net m n hâ‚‚
          exact IH Lm hâ‚ƒ m hLm

    ---------------------
    -- Forward Direction
    -- (similar, but differs slightly in Case 1)
    ---------------------
    -- This direction is a bit more tricky. This
    -- is where we rely on the net being fully
    -- connected & transitively closed.
    case mp => 
      intro hâ‚
      
      -- By cases; either n âˆˆ B âˆª reachable net (propagate net A) B, 
      -- or not.
      by_cases n âˆˆ B âˆª reachable net (propagate net A) (propagate net B)
      case pos => 
        -- In this case, just apply propagate_is_extens
        rw [â† hL]
        rw [hebb_layers]
        simp only [propagate] at h
        exact propagate_acc_is_extens _ _ h

      case neg hâ‚‚ => 
        -- From here, we split *again*, depending on whether n âˆˆ Prop(A).
        by_cases n âˆˆ propagate net A

        ---------------------
        -- Case 1: n âˆˆ Prop(A)
        ---------------------
        case pos => 
          -- Since Prop(A) âˆ© Prop(B) is nonempty, there is an m
          -- in the intersection.
          have hâ‚ƒ : âˆƒ m, m âˆˆ propagate net A âˆ§ m âˆˆ propagate net B :=
            Set.inter_nonempty_iff_exists_left.mp
              (Set.nonempty_iff_ne_empty.mpr h_nonempty)
          
          match hâ‚ƒ with
          | âŸ¨m, hmâŸ© => 
            -- Moreover, this m is the *smallest* such m âˆˆ Prop(A)
            have hâ‚„ : âˆ€ x, x âˆˆ propagate net A â†’
              layer net m â‰¤ layer net x := by
              sorry
            
            cases eq_or_lt_of_le (hâ‚„ n h)
            
            ---------------------
            -- Case 1.1: n âˆˆ Prop(A)
            -- and layer[m] < layer[n]
            ---------------------
            -- In this case, since the net is transitively closed
            -- (fully connected), we have an edge from m âˆˆ Prop(A) âˆ© Prop(B)
            -- to n âˆˆ Prop(A).  This gives us n âˆˆ Reach(Prop(A), Prop(B)).
            case inr hâ‚… =>
              -- Since the net is fully connected, there is an edge mâŸ¶n.
              -- So we just provide the path from mâŸ¶n.
              have hâ‚† : n âˆˆ reachable net (propagate net A) (propagate net B) := by
                exact âŸ¨m, âŸ¨hm.2, 
                  focusedPath.from_path (focusedPath.trivial hm.1) 
                    (connected _ m n hâ‚…) hâŸ©âŸ©

              -- Since n âˆˆ Reach(...),
              -- We conclude that n âˆˆ Prop(B âˆª Reach(...))
              simp only [propagate] at hâ‚†
              rw [â† hL]
              exact propagate_acc_is_extens net _ 
                (Set.mem_union_right _ hâ‚†)

            ---------------------
            -- Case 1.2: n âˆˆ Prop(A)
            -- and layer[m] = layer[n]
            ---------------------
            -- In this case, the activ's are the same, so
            -- we can straightforwardly apply our inductive
            -- hypothesis.
            case inl hâ‚… => 
              -- First, we show that any predecessor of n
              -- cannot be in Prop(A).
              have hâ‚† : âˆ€ x, x âˆˆ preds net n â†’ x âˆ‰ propagate net A := by
                rw [hâ‚…] at hâ‚„
                exact fun x hx x_in_propA => 
                  absurd (hâ‚„ x x_in_propA) (not_le.mpr (preds_decreasing _ _ _ hx))

              -- We get ready to simplify propagate_acc
              rename_i n_not_in_reach
              have n_not_in_B : n âˆ‰ B :=
                fun n_in_B => absurd (Set.mem_union_left _ n_in_B) n_not_in_reach

              -- Simplifications and rewriting, to prepare for IH
              -- We also rewrite the 'preds', 'layers', and 'activ'
              -- for (hebb_star net) in terms of the original 'net'.
              simp only [propagate] at n_not_in_reach
              rw [simp_propagate_acc _ n_not_in_B] at hâ‚
              rw [simp_propagate_acc _ n_not_in_reach]
              
              -- TODO: Use hebb_activâ‚‚, which says that if all
              -- of the preds âˆ‰ Prop(A), the activ's are the same.
              rw [hebb_activâ‚‚ _ _ _ hâ‚†] at hâ‚ -- rewrite 'activ'
              rw [hebb_preds net A] at hâ‚ -- rewrite 'preds'
              conv at hâ‚ => -- rewrite 'layers'
                enter [2, 2, i, m, 1]
                rw [hebb_layers net A]
              simp
              simp at hâ‚
              convert hâ‚ using 5
              rename_i i
              generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
              generalize hLm : layer net m = Lm
              
              -- We are now ready to apply our inductive hypothesis!
              have hâ‚‡ : m âˆˆ preds net n := by
                rw [symm hm]
                simp [preds]
                exact get!_mem (predecessors net.toNet.graph n).data i
              have hâ‚ˆ : Lm â‰¤ L := by
                rw [symm hLm]
                apply Nat.lt_succ.mp
                rw [symm hL]
                rw [hebb_layers net A]
                exact preds_decreasing net m n hâ‚‡
              exact (symm (IH Lm hâ‚ˆ m hLm).to_eq).to_iff
        
        ---------------------
        -- Case 2: n âˆ‰ Prop(A)
        ---------------------
        -- In this case, the activ's are the same, so we can
        -- straightforwardly apply our inductive hypothesis.

        case neg =>
          -- We get ready to simplify propagate_acc
          rename_i n_not_in_reach
          have n_not_in_B : n âˆ‰ B :=
            fun n_in_B => absurd (Set.mem_union_left _ n_in_B) n_not_in_reach

          -- Simplifications and rewriting, to prepare for IH
          -- We also rewrite the 'preds', 'layers', and 'activ'
          -- for (hebb_star net) in terms of the original 'net'.
          simp only [propagate] at n_not_in_reach
          rw [simp_propagate_acc _ n_not_in_B] at hâ‚
          rw [simp_propagate_acc _ n_not_in_reach]
          
          rw [hebb_activâ‚ _ _ _ h] at hâ‚ -- rewrite 'activ'
          rw [hebb_preds net A] at hâ‚ -- rewrite 'preds'
          conv at hâ‚ => -- rewrite 'layers'
            enter [2, 2, i, m, 1]
            rw [hebb_layers net A]
          simp
          simp at hâ‚
          convert hâ‚ using 5
          rename_i i
          generalize hm : List.get! (predecessors net.toNet.graph n).data i = m
          generalize hLm : layer net m = Lm
          
          -- We are now ready to apply our inductive hypothesis!
          have hâ‚‚ : m âˆˆ preds net n := by
            rw [symm hm]
            simp [preds]
            exact get!_mem (predecessors net.toNet.graph n).data i
          have hâ‚ƒ : Lm â‰¤ L := by
            rw [symm hLm]
            apply Nat.lt_succ.mp
            rw [symm hL]
            rw [hebb_layers net A]
            exact preds_decreasing net m n hâ‚‚
          exact (symm (IH Lm hâ‚ƒ m hLm).to_eq).to_iff
        

-- TODO: Prove that we can unravel these nets into ordinary
-- feedforward nets
-- 
-- TODO: Email David Sprunger about follow-up papers to
-- "backprop as a functor"

/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  The Logic (Language and Semantics)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/



/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Inference Rules and Proof System
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/




/-â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Soundness
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•-/



